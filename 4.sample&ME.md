

## 四、sample&ME

### *（-）随机模拟*

#### 1.逆函数法

​	令u~1~ ,...,u~K~ ,服从均匀分布，让x~1~ = $F^{-1}$ (u~1~),x~k~ = $F^{-1}$ (u~k~)，那么x~i~ 服从分布F。
~~~SCALA
//指数分布随机数
import org.apache.log4j.{Level, Logger}
import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark.mllib.random.RandomRDDs._

val conf = new SparkConf().setAppName("run").setMaster("local[2]")
val sc = new SparkContext(conf)
val unif = uniformRDD(sc,1000,1).map(x => -math.log(x))
print(unif)
import java.util.concurrent.ThreadLocalRandom
val r = ThreadLocalRandom.current()
print(r)
val OurExpRVs = (1 to 1000).map( x =>r.nextDouble).map(x => -math.log(x)).toArray[Double]
~~~

~~~scala
//服从拉普拉斯分布随机数
val unif1 = uniformRDD(sc,1000,1).map(x=>if (x<0.5) math.log(2*x);
else 2*math.log(1-x))
unif1.foreach(print)
~~~



#### 2.拒绝接受法

+ 找到c与g(x)，使得$f(x)\leq cg(x)$ 在二者的定义域内恒成立

+ 产生密度函数是$g_y$ 的随机数$y_i$ ，以及服从均匀分布的随机数$u_i$

+ 如果$u_i \leq\frac {f(x)}{cg(x)}$成立，那么认为此$y_i$ 是来自$f(x)$ 的分布。

+ 因为可以证明的是$f(x|U\leq U(y)) = f(x)​$

+ c越小，接受度越高

+ $c_{optimal} = min_\theta  max_x\frac {f(x)}{g_{\theta}(x)}​$

+ 拉普拉斯分布可以用来产生正态分布随机数



#### 3.重要抽样法（SIR）

+ $w(X^{(j)})=\frac {f(X^{(j)})}{g(X^{(j)})} ​$,计算每个样本的权重，以及对应概率$w_j = \frac {w(X^{(j)})}{\sum_{i=1}^{100}{w(X^{(i)})}}​$

+ 生成i.i.d的备选样本$x_1,....,x_n​$ 服从$g(x)​$

+ 以概率$w_j$ 再从$x_1,....,x_n$ 抽出m个样本

+ 此时的$x_i(i=1,..,m)$近似服从$f(x)$

+ $j/m$ ，越大越好，一般来说1要大于10或20

  

### *（二）EM算法，缺失不完全数据处理*

#### 1.原理

​	EM算法可以用来处理缺失数据的极大似然估计。其推到过程如下：

![](https://github.com/HenaChris/-/blob/master/EM1.jpg?raw=true)



![](https://github.com/HenaChris/-/blob/master/EM2.jpg?raw=true)



#### 2.应用

​	考虑解决高斯混合模型的EM算法。服从高斯混合模型分布的数据来自第k个正态分布$N(\mu_k,\Sigma_k)$ ，的概率为$\pi_k$ 。即$x_i$ ~ $\sum_{k=1}^{K}\pi_kN(\mu_k,\Sigma_k)$,1中$i = 1,....,n$ 

 

![EM_gaussian1](D:\研一下\分布式统计\笔记\EM_gaussian1.jpg)

![EM_gaussian2](D:\研一下\分布式统计\笔记\EM_gaussian2.jpg)

![EM_gaussian3](D:\研一下\分布式统计\笔记\EM_gaussian3.jpg)

​	假设从0.2N(5,4)+0.8N(0,1)中产生10000随机数，利用EM算法估计相关参数。

~~~scala
import org.apache.spark.{SparkConf, SparkContext}
import java.util.concurrent.ThreadLocalRandom

import breeze.stats.distributions.Beta.SufficientStatistic
val conf = new SparkConf().setAppName("run").setMaster("local[2]")
val sc = new SparkContext(conf)
// 设置基本参数
val N=10000
val MU1 = 5.0
val Sig1 = 2.0
val MU2 = 0.0
val Sig2 = 1.0
val P = 0.2
val NumofSlaves = 5
val eps = 0.000001
//产生数据

val random = ThreadLocalRandom.current
val data = Array.ofDim[Double](N)
//创建一组长度为N的数组

for(i <- 0 until N)
  {data(i) = if(random.nextDouble <= P)
                MU1 + Sig1*random.nextGaussian
            else MU2 + Sig2*random.nextGaussian}
//生成混合高斯分布的样本

var ParData = sc.parallelize(data,NumofSlaves)
val ParDataStr = ParData.map("%.4f" format _)
ParData = ParDataStr.map(_.toDouble)
//将数据产生后先转化为RDD格式，然后再将其转化为文本格式，再转化为Double类型，
//这是为了防止随机数无法序列化带来的问题

//设置初始值
val InitialP = 0.5
var Nk = N.toDouble*InitialP
var EstMu1 = ParData.reduce((x,y)=>x+y)/N.toDouble
var EstSig1 = math.sqrt(ParData.map(x=>x*x).reduce((x,y)=>x+y)/N.toDouble - EstMu1*EstMu1)
var EstMu2 = EstMu1 - 1.0
var EstSig2 = EstSig1
var Diff = 0.0
var OldEstMu1 = 0.0
var OldEstMu2 = 0.0
var OldEstSig1 = 0.0
var OldEstSig2 = 0.0
var ii= 0

//EM算法迭代
do{
   ii += 1
  OldEstMu1 = EstMu1
  OldEstMu2 = EstMu2
  OldEstSig1 = EstSig1
  OldEstSig2 = EstSig2

  /*计算充分统计量所需的值，包括原始数据，条件概率，所有充分统计量对应于每个观察值数量*/
  var sufficientStatistics = ParData.map(line => {
    val x1 = -math.pow((line - EstMu2) / EstSig2, 2) / 2.0
    val x2 = -math.pow((line - EstMu1) / EstMu1, 2) / 2.0
    val gamma = Nk * EstSig2 / (Nk * EstSig2 + (N - Nk) * EstSig1 * math.exp(x1 - x2))
    (line, gamma, line * gamma, line * line * gamma, 1 - gamma, line * (1 - gamma), line * line * (1 - gamma))
  })
  
//计算分布式计算数量加以汇总得到的期望充分统计量
  val Results = sufficientStatistics.reduce((x,y)=>
    (x._1+y._1,x._2+y._2,x._3+y._3,x._4+y._4,x._5+y._5,x._6+y._6,x._7+y._7))
  Nk = Results._2
  EstMu1 = Results._3/Nk
  EstSig1 = math.sqrt(Results._4/Nk-EstMu1*EstMu1)
  EstMu2 = Results._6/Results._5
  EstSig2 = math.sqrt(Results._7/Results._5 - EstMu2*EstMu2)

  //记录参数估计更新的变化以判断是否终止循环
  Diff = math.abs(EstMu1-OldEstMu1)+math.abs(EstMu2-OldEstMu2)
  Diff += math.abs(EstSig1 - OldEstSig2) + math.abs(EstSig2 - OldEstSig2)
}while(Diff > eps)

print(EstMu1)
print(EstMu2)
print(EstSig1)
print(EstSig2)

~~~



#### 3.参考链接

https://blog.csdn.net/lin_limin/article/details/81048411	"详解EM算法与混合高斯模型(Gaussian mixture model, GMM)"
https://blog.csdn.net/fukaiqi1010/article/details/81166575	"GMM+EM算法+拉格朗日乘子"

